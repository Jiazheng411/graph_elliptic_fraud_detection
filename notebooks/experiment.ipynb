{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710654ea",
   "metadata": {},
   "source": [
    "Reproduce random forest baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109bb1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data all: (136265, 169), Train data labeled: (29894, 169)\n",
      "Test data all: (67504, 169), Test data labeled: (16670, 169)\n",
      "Train edges all: (156843, 3), Train edges labeled: (22898, 3)\n",
      "Test edges all: (77512, 3), Test edges labeled: (13726, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txs_classes = pd.read_csv('../data/elliptic_txs_classes.csv')\n",
    "txs_edges = pd.read_csv('../data/elliptic_txs_edgelist.csv')\n",
    "txs_features = pd.read_csv('../data/elliptic_txs_features.csv', header=None)\n",
    "\n",
    "\n",
    "# join features with classes using tx id (1st column of txs_features)\n",
    "txs_data = txs_features.merge(txs_classes, left_on=0, right_on='txId', how='left')\n",
    "\n",
    "# convert class labels to integers\n",
    "label_mapping = {'1': 0, '2': 1, 'unknown': -1}\n",
    "txs_data['class'] = txs_data['class'].map(label_mapping).astype(int)\n",
    "\n",
    "# split data and edges into train and test according to timestep (2nd column of txs_features)\n",
    "train_data_all = txs_data[txs_data[1] <= 34]\n",
    "test_data_all = txs_data[txs_data[1] > 34]\n",
    "\n",
    "# separate datasets with labels(1 or 2) from those without labels(class=unknown)\n",
    "train_data_labeled = train_data_all[train_data_all['class'].isin([0, 1])]\n",
    "test_data_labeled = test_data_all[test_data_all['class'].isin([0, 1])]\n",
    "\n",
    "# process edges like data: add timestep info and split into train and test\n",
    "txs_edges = txs_edges.merge(txs_features[[0, 1]], left_on='txId1', right_on=0, how='left').rename(columns={1: 'timestep'}).drop(columns=[0])\n",
    "train_edges_all = txs_edges[txs_edges['timestep'] <= 34]\n",
    "test_edges_all = txs_edges[txs_edges['timestep'] > 34]\n",
    "train_edges_labeled = train_edges_all[train_edges_all['txId1'].isin(train_data_labeled['txId']) & train_edges_all['txId2'].isin(train_data_labeled['txId'])]\n",
    "test_edges_labeled = test_edges_all[test_edges_all['txId1'].isin(test_data_labeled['txId']) & test_edges_all['txId2'].isin(test_data_labeled['txId'])]\n",
    "\n",
    "# print sizes of datasets\n",
    "print(f\"Train data all: {train_data_all.shape}, Train data labeled: {train_data_labeled.shape}\")\n",
    "print(f\"Test data all: {test_data_all.shape}, Test data labeled: {test_data_labeled.shape}\")\n",
    "print(f\"Train edges all: {train_edges_all.shape}, Train edges labeled: {train_edges_labeled.shape}\")\n",
    "print(f\"Test edges all: {test_edges_all.shape}, Test edges labeled: {test_edges_labeled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1431c3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Report on Labeled Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     illicit       0.89      0.72      0.80      1083\n",
      "       licit       0.98      0.99      0.99     15587\n",
      "\n",
      "    accuracy                           0.98     16670\n",
      "   macro avg       0.94      0.86      0.89     16670\n",
      "weighted avg       0.98      0.98      0.98     16670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# licit node class=1, illicit node class=0\n",
    "# train and evaluate a random forest classifier on the train and test data with labels\n",
    "# n_estimators=50, max_features=50\n",
    "# evaluate on both licit and illicit nodes' precision and recall and f1-score, also include micro and macro averages\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features=50, random_state=42)\n",
    "clf.fit(train_data_labeled.iloc[:, 2:-2], train_data_labeled['class'])\n",
    "test_preds = clf.predict(test_data_labeled.iloc[:, 2:-2]) \n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(test_data_labeled['class'], test_preds, target_names=['illicit', 'licit'])\n",
    "print(\"Random Forest Classifier Report on Labeled Test Data:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa83c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labeled graph: Graph(num_nodes=29894, num_edges=22898,\n",
      "      ndata_schemes={'feat': Scheme(shape=(165,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "Test labeled graph: Graph(num_nodes=16670, num_edges=13726,\n",
      "      ndata_schemes={'feat': Scheme(shape=(165,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "Train all graph: Graph(num_nodes=136265, num_edges=156843,\n",
      "      ndata_schemes={'feat': Scheme(shape=(165,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n",
      "Test all graph: Graph(num_nodes=67504, num_edges=77512,\n",
      "      ndata_schemes={'feat': Scheme(shape=(165,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "# create DGL graphs for train and test data\n",
    "def create_dgl_graph(data, edges):\n",
    "    node_ids = data['txId'].tolist()\n",
    "    id_to_idx = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
    "    \n",
    "    src = edges['txId1'].map(id_to_idx).tolist()\n",
    "    dst = edges['txId2'].map(id_to_idx).tolist()\n",
    "    \n",
    "    g = dgl.graph((src, dst), num_nodes=len(node_ids))\n",
    "    features = torch.tensor(data.iloc[:, 2:-2].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(data['class'].values, dtype=torch.long)\n",
    "    \n",
    "    g.ndata['feat'] = features\n",
    "    g.ndata['label'] = labels\n",
    "    \n",
    "    return g\n",
    "\n",
    "train_labeled_graph = create_dgl_graph(train_data_labeled, train_edges_labeled)\n",
    "test_labeled_graph = create_dgl_graph(test_data_labeled, test_edges_labeled)\n",
    "train_all_graph = create_dgl_graph(train_data_all, train_edges_all)\n",
    "test_all_graph = create_dgl_graph(test_data_all, test_edges_all)\n",
    "\n",
    "print(f\"Train labeled graph: {train_labeled_graph}\")\n",
    "print(f\"Test labeled graph: {test_labeled_graph}\")\n",
    "print(f\"Train all graph: {train_all_graph}\")\n",
    "print(f\"Test all graph: {test_all_graph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "168df220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: Loss 0.6558, Train F1 0.1194, Test Loss 0.7959, Test F1 0.1635\n",
      "Epoch 100: Loss 0.1586, Train F1 0.8169, Test Loss 0.2861, Test F1 0.4778\n",
      "Epoch 200: Loss 0.1239, Train F1 0.8556, Test Loss 0.2756, Test F1 0.5328\n",
      "Epoch 300: Loss 0.1059, Train F1 0.8783, Test Loss 0.2819, Test F1 0.5584\n",
      "Epoch 400: Loss 0.0929, Train F1 0.8931, Test Loss 0.2973, Test F1 0.5891\n",
      "Epoch 500: Loss 0.0828, Train F1 0.9032, Test Loss 0.3145, Test F1 0.6106\n",
      "Epoch 600: Loss 0.0752, Train F1 0.9115, Test Loss 0.3327, Test F1 0.6204\n",
      "Epoch 700: Loss 0.0691, Train F1 0.9177, Test Loss 0.3466, Test F1 0.6226\n",
      "Epoch 800: Loss 0.0642, Train F1 0.9242, Test Loss 0.3591, Test F1 0.6269\n",
      "GCN Classification Report on Labeled Test Graph:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     illicit       0.77      0.53      0.63      1083\n",
      "       licit       0.97      0.99      0.98     15587\n",
      "\n",
      "    accuracy                           0.96     16670\n",
      "   macro avg       0.87      0.76      0.80     16670\n",
      "weighted avg       0.96      0.96      0.96     16670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "# Train a 2-layer GCN on the labeled subgraphs\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "class_weights = torch.tensor([0.7, 0.3], dtype=torch.float32, device=device)\n",
    "embedding_dim = 100\n",
    "num_epochs = 800\n",
    "\n",
    "labeled_only = True\n",
    "\n",
    "if labeled_only:\n",
    "    train_graph = dgl.to_bidirected(train_labeled_graph, copy_ndata=True)\n",
    "    test_graph = dgl.to_bidirected(test_labeled_graph, copy_ndata=True)\n",
    "else:\n",
    "    train_graph = dgl.to_bidirected(train_all_graph, copy_ndata=True)\n",
    "    test_graph = dgl.to_bidirected(test_all_graph, copy_ndata=True)\n",
    "\n",
    "train_graph = dgl.add_self_loop(train_graph)\n",
    "test_graph = dgl.add_self_loop(test_graph)\n",
    "train_features = train_graph.ndata['feat']\n",
    "train_labels = train_graph.ndata['label']\n",
    "train_mask = (train_labels >= 0)\n",
    "test_features = test_graph.ndata['feat']\n",
    "test_labels = test_graph.ndata['label']\n",
    "test_mask = (test_labels >= 0)\n",
    "\n",
    "train_graph = train_graph.to(device)\n",
    "test_graph = test_graph.to(device)\n",
    "train_features = train_features.to(device)\n",
    "train_labels = train_labels.to(device)\n",
    "test_features = test_features.to(device)\n",
    "test_labels = test_labels.to(device)\n",
    "\n",
    "torch.manual_seed(42) \n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConv(in_feats, hidden_size)\n",
    "        self.conv2 = GraphConv(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, g, feat):\n",
    "        h = self.conv1(g, feat)\n",
    "        h = torch.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "model = GCN(train_features.shape[1], embedding_dim, 2).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights,ignore_index=-1)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    logits = model(train_graph, train_features)\n",
    "    loss = criterion(logits, train_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch == 1 or epoch % 100 == 0:\n",
    "        train_pred = logits.argmax(dim=1)\n",
    "        train_precision = ((train_pred[train_mask] == 0) & (train_labels[train_mask] == 0)).sum().item() / (train_pred[train_mask] == 0).sum().item()\n",
    "        train_recall = ((train_pred[train_mask] == 0) & (train_labels[train_mask] == 0)).sum().item() / (train_labels[train_mask] == 0).sum().item()\n",
    "        train_f1 = 2 * train_precision * train_recall / (train_precision + train_recall)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_logits = model(test_graph, test_features)\n",
    "            test_pred = test_logits.argmax(dim=1)\n",
    "            test_loss = criterion(test_logits, test_labels).item()\n",
    "            # report F1-score, precision, recall on illicit node only\n",
    "            test_precision = ((test_pred[test_mask] == 0) & (test_labels[test_mask] == 0)).sum().item() / (test_pred[test_mask] == 0).sum().item()\n",
    "            test_recall = ((test_pred[test_mask] == 0) & (test_labels[test_mask] == 0)).sum().item() / (test_labels[test_mask] == 0).sum().item()\n",
    "            test_f1 = 2 * test_precision * test_recall / (test_precision + test_recall)\n",
    "        print(f\"Epoch {epoch:03d}: Loss {loss.item():.4f}, Train F1 {train_f1:.4f}, Test Loss {test_loss:.4f}, Test F1 {test_f1:.4f}\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_logits = model(test_graph, test_features)\n",
    "test_preds = test_logits.argmax(dim=1).cpu().numpy()\n",
    "test_true = test_labels.cpu().numpy()\n",
    "\n",
    "print(\"GCN Classification Report on Labeled Test Graph:\")\n",
    "print(classification_report(test_true[test_mask.cpu().numpy()], test_preds[test_mask.cpu().numpy()], target_names=['illicit', 'licit']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
